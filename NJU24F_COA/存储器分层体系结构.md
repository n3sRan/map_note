# 存储器分层体系结构

> 笔记基于23年王道计算机考研: 计算机组成原理的网课3.\*内容, 结合24秋NJU的COA课程的PPT以及该课程的往年笔记整理而来.

[TOC]

## 存储系统基本概念

### 层次结构

- 主存和辅存交换数据: 硬件+操作系统实现页面置换算法 (实现虚拟存储系统, 解决了主存容量不够的问题)
- 主存和cache交换数据: 硬件自动完成 (软件程序员不用关心) (解决了主存和CPU速度不匹配的问题)

### 存储器分类

- 介质
  - 半导体存储器
  - 磁表面存储器
  - 光存储器
- 存取方式
  - 随机存取 RAM Random-Access Memory
  - 顺序存取 SAM
  - 直接存取 DAM (SAM, DAM 串行访问存储器: 读写某个存储单元所需时间与存储单元的物理位置有关)
  - 相连存储器 (CAM) 按照内容访问的存储器
- 信息的可更改性
  - 读写
  - 只读 ROM
- 信息的可保存性
  - 易失性 Volatile (主存, cache)
  - 非易失性 (磁盘, 光盘)
  - 破坏性读出 (DRAM 读出数据后要重写)
  - 非破坏性读出 (SRAM, 磁盘, 光盘)

### 存储器的性能指标

- 存储容量: 存储字数 × 字长
- 单位成本: 每bit价格
-  存储速度: 数据传输率 (主存带宽 B_m 单位 字/s B/s b/s) = 数据的宽度 (存储字长) / 存储周期
  - 存取时间 T_a
  - 恢复时间
  - 存储周期 (可以连续读/写的最短时间间隔) T_m = 存取时间 + 恢复时间

## 主存储器的基本组成

### 基本原件

- 存储元 (位元 memory cell): 
  - MOS管: 通电开关
  - 电容: 存储电荷 0/1

### 存储器芯片的结构

- 一个**存储芯片** (存储矩阵, 存储体) 由多个**存储单元** (即存储字, 存储器每一次读或写的一个单位都是一个存储字) 构成.
- 一个**存储单元**又由多个**存储元** (存放1位的0或1) 构成.

过程: 地址总线 -> MAR -> 译码器 -> 存储体

总容量 = 存储单元个数 x 存储字长

控制电路: 控制 MAR, 译码器, MDR

CS 芯片选择/CE 芯片使能

片选线 (加bar表示低电平有效) 

读/写控制线 (两根: 低电平允许; 一根: 低电平写)

译码驱动电路:驱动器: 放大译码器信号

一个内存条可能包含多块存储芯片 (片选线)

例: 判断存储**芯片引脚**数目 (地址线(位数) 总共有多少根 数据线总共有多少根 读写控制线 片选线 供电 接地)

a×b位的存储芯片: a表示存储单元个数, b表示存储字长

### 寻址

按字节 字 半字 双字寻址

## DRAM和SRAM

### 对比

- DRAM Dynamic Random Access Memory 动态RAM (上一节的结构)
  - 读出数据时, 电容放电导致信息被破坏
  - 常用作主存
- SRAM Static Random Access Memory 静态RAM
  - 6个MOS管 1:A高B低 0:A低B高, 读出数据时, 触发器状态保持稳定
  - 常用作cache

|  类型特点   |     DRAM     |   SRAM   |
| :---------: | :----------: | :------: |
|  存储信息   | 双稳态触发器 | 栅极电容 |
| 破坏性读出  |      非      |    是    |
|  需要重写   |      非      |    是    |
|  运行速度   |      快      |    慢    |
|   集成度    |      低      |    高    |
|   发热量    |      大      |    小    |
|  存储成本   |      高      |    低    |
| 易失/非易失 |     易失     |   易失   |
|  需要刷新   |    不需要    |   需要   |
| 送行列地址  |    同时送    | 分两次送 |

### DRAM的刷新

#### 多久刷新一次? 

- 刷新周期: 一般为2ms

#### 每次刷新多少存储单元?

- 每次刷新**一行存储单元**

#### 什么是行列地址?

- 存储器简单模型: 译码器连接 $2^n$ 根选通线 (工程上比较难实现)
- 将存储单元排列成 $2^{n/2} × 2^{n/2}$的矩阵
- 将地址拆分位登长的行列地址分别交给行地址译码器和列地址译码器选择
- 减少选通线的数量, 使电路变得更简单和清晰
- 发展: 三维排列

#### 如何刷新?

- 刷新电路 (硬件) 读出一行的信息后重新写入, 占用一个读/写周期 (也叫存/取周期)

#### 什么时候刷新?

- 分散刷新 (Centralized refresh): 每次读写完都刷新一行 (逐行刷新, 即读写的和刷新的不一定是同一行), 使读写时间翻倍
- 集中刷新 (Decentralized refresh): 2ms内集中安排时间, 存取周期不变, 但有一段时间专门用于逐行刷新, 无法访问存储器, 称为访存"**死区**"
- 异步刷新 (Asynchronous refresh): 2ms内保证每行刷新一次即可 (将"死时间"分散, 可在译码阶段刷新, 有效避免死区), 效率高, 常用

### DRAM地址线复用技术

将n位地址分两次送 (行列地址), 将地址线由n减少为n/2, 也让引脚数目更少

### DDR SDRAM

DDR Double Data Rate: 每个时钟周期发送两次数据, 一次在时钟脉冲的上升沿, 一次在下降沿

优化: 增加操作频率和预取缓冲区 (主要提升的是带宽)

现在主流的主存通常采用SDRAM (DDR3, DDR4)

## 只读存储器ROM

### ROM类型

MROM (Mask Read-Only Memory) 掩模式只读存储器 厂家按需求写入, 任何人不能重写

PROM 可编程只读存储器, 用户写入, 写一次后就不可更改

EPROM 允许用户写入, 可用某种方式擦除, 可进行多次重写

UVEPROM 紫外线照射, 擦除所有信息

EEPROM "电擦除", 擦除特定的字

Flash Memory 闪存 可进行多次快速擦除重写 (写比读慢) 位密度比RAM高

SSD 固态硬盘

### 计算机内重要ROM

主板上BIOS芯片 (也是主存的一部分, 被CPU统一编址): 存储了"自举装入程序", 负责引导装入操作系统 (安装在辅存)

## 双端口RAM和多模块存储器

存取周期 T  = 存取时间 r + 恢复时间

### 双端口RAM

优化多核CPU访问一根内存条的速度

总线设计更复杂

两个端口不能同时**对同一地址**写入数据, 也不能一读一写

### 多体并行存储器

高位交叉编址

低位交叉编址: 优化连续读取连续地址

取几个"体"?

"流水线"式并行存取(宏观上并行, 微观上串行)

存取周期T, 存取时间 (总线传输周期) r, 模块数 m = T/r

### 多模块存储器

- 多体并行
- 既能并行也能交叉工作
- 单体多字
- 每个存储单元存储m个字 (每次也只能同时取m个字)

## 主存储器与CPU的连接

现在的计算机: MDR和MAR集成进CPU, MDR通过数据总线与主存交换, MAR通过地址总线与主存交换, CPU还向主存发送读/写控制信息

### 存储器芯片的基本结构

- 译码驱动电路
- 存储矩阵
- 读写电路
- 对外暴露 (与CPU连接): 地址线, 数据线, 片选线, 读写控制线 (注意是高电平有效还是低电平有效, 低加bar)

### 位扩展

增加主存的存储字长

### 字扩展

增加主存的存储字数

- 线选法: n条线对应n个选片信号 电路简单 地址空间不连续
- 译码器片选法: n条线对应2^n个选片信号 电路复杂 地址空间可连续

译码器

- 高电平有效
- 低电平有效
- 使能端 Enable (类似于CS) 多个 (CPU可使用译码器的使能端控制片选信号的生效时间, CPU的MREQ信号)

### 字位同时扩展

扩展主存容量

## 磁盘存储器

### 原理

磁表面存储: 每次只能读或写1bit, 串行/并行转换, 读写不能同时进行

#### 磁盘设备的组成

存储区域: 磁头, 柱面, 扇区, 一块磁盘含有若干个记录面, 每个记录面划分为若干条磁道, 每条磁道又划分为若干个扇区, 扇区 (也称块) 是磁盘读写的最小单位, 即磁盘按块存取 (磁头数 柱面数 扇区数)

硬盘存储器: 由磁盘驱动器, 磁盘控制器和盘片组成

#### 性能指标

- 容量: 
  - 非格式化: 可磁化单元总数
  - 格式化:
- 记录密度:
  - 道密度: 半径方向:单位长度上的磁道数
  - 位密度: 磁道单位长度上能记录的二进制代码位数 (越靠近内测位密度越大)
  - 面密度: 位密度和道密度的乘积
- 平均存取时间
  - 寻道时间 seek time + 旋转延迟时间 rotational delay (平均: 磁头转半圈) + 传输时间 transfer time (+ 磁盘控制器延迟)
- 数据传输率
  - 单位时间内向主机传送数据的字节数 磁盘转速r转/秒, 每条磁道容量N个字节, 则数据传输率 $D_r = rN$

#### 磁盘地址

驱动器号 柱面号(磁道) 盘面号 扇区号

#### 硬盘的工作过程

寻址, 读盘, 写盘

每个操作对应一个控制字

并-串变换电路

### 冗余磁盘阵列

*扩展: COA课件第10讲内容 (王道网课较为简略故不计入)*

RAID, Redundant Arrays of Independent Disks 廉价冗余磁盘阵列

基本思想

- 将多个独立操作的磁盘按某种方式组织成磁盘阵列, 以增加容量
- 将数据存储在多个盘体上, 通过这些盘并行工作来提高数据传输率
- 采用数据冗余来进行错误恢复以提高系统可靠性

特性

- 由一组物理磁盘驱动器组成, 被视为单个逻辑驱动器
- 数据是分布在多个物理磁盘上
- 冗余磁盘容量用于存储校验信息, 保证磁盘万一损坏时能恢复数据

分类

![[../0_Attachment/image-20241126110945418.png]]

#### RAID 0

- 数据以**条带**的形式在可用的磁盘上分布, 条带大小自定义, 16-512KB
- 不采用冗余来改善性能 (不是RAID家族中的真正成员)
- 与**单个**大容量磁盘相比
  - 高数据传输率
  - 高速响应I/O请求: 两个I/O请求所需要的数据块可能在不同的磁盘上

#### RAID 1

- 采用了数据条带
- 采用简单地备份所有数据的方法来实现冗余 (复制一份)
- 优点
  - 高速响应I/O请求: 即便是同一个磁盘上的数据块, 也可以由两组硬盘**分别**响应
  - 读请求可以由包含请求数据的两个对应磁盘中的某一个提供服务, 可以选择寻道时间较小的那个
  - 写请求需要更新两个对应的条带: 可以**并行**完成, 但受限于写入较慢的磁盘
  - 单个磁盘损坏时不会影响数据访问, 恢复受损磁盘简单
- 缺点: 贵
- 用途: 只限于用在存储系统软件, 数据和其他关键文件的驱动器中
- 与RAID 0 相比
  - 如果有大批的**读**请求, 则RAID 1能实现高速的I/O速率, 性能可以达到RAID 0的两倍
  - 如果I/O请求有相当大的部分是**写**请求, 则不比RAID 0的性能好多少
- RAID 01 vs. RAID 10: 两者在数据传输率和磁盘利用率上没有明显区别, 主要区别是对磁盘损坏的容错能力 (后者更好)

#### RAID 2

![[../0_Attachment/image-20241126105244705.png]]

- 采用**并行存取**技术 (前4数据盘, 后3校验盘)
- 目标: 所有磁盘都参与每个I/O请求的执行
- 特点
  - 各个驱动器的轴是同步旋转的, 因此每个磁盘上的每个磁头在任何时刻都位于同一位置
  - 采用数据条带: 条带非常小, 经常只有一个字节或一个字
- 纠错: 对位于同一条带的各个数据盘上的数据位计算校验码 (通常采用海明码), 校验码存储在该条带中多个校验盘的对应位置
- 访问
  - 读取: 获取请求的数据和对应的校验码
  - 写入: 所有数据盘和校验盘都被访问
- 缺点
  - 冗余盘依然比较多, 价格较贵
  - 适用于多磁盘易出错环境, 对于单个磁盘和磁盘驱动器已经具备高可靠性的情况没有意义, 实际基本弃用

#### RAID 3

![[../0_Attachment/image-20241126105224177.png]]

- 采用**并行存取**技术, 各个驱动器的轴同步旋转, 采用非常小的数据条带
- 校验: 对所有数据盘上同一位置的数据计算奇偶校验码, 当某一磁盘损坏时, 可以用于重构数据
- 优点: 能够获得非常高的数据传输率, 对于大量读请求, 性能改善特别明显
- 缺点: 一次只能执行一个I/O请求, 在面向多个IO请求时, 性能将受损

#### RAID 4

![[../0_Attachment/image-20241126105209048.png]]

- 采用**独立存取**技术, 每个磁盘成员的操作是独立的, 各个I/O请求能够并行处理, 采用相对较大的数据条带 (常见的是4KB)
- 校验: 根据各个数据盘上的数据来逐位计算奇偶校验条带, 奇偶校验位存储在奇偶校验盘的对应条带上
- 性能
  - 当执行较小规模的I/O写请求时, RAID 4会遭遇写损失
  - 对于每一次写操作, 阵列管理软件不仅要修改用户数据, 而且要修改相应
    的校验位
  - 当涉及所有磁盘的数据条带的较大I/O写操作时, 只要用新的数据位来进行简单
    的计算即可得到奇偶校验位
  - 每一次写操作必须涉及到唯一的校验盘, 校验盘会成为瓶颈 (实际没使用过)

#### RAID 5

![[../0_Attachment/image-20241126110045615.png]]

- 与RAID 4 组织方式相似, 常用
- 校验: 在所有磁盘上都分布了**奇偶校验条带**, 避免潜在的I/O瓶颈问题
- 访问: "两读两写", 读在写前, 读/写不需要并行
- RAID 50
  - 先作RAID5, 再作RAID0, 也就是对多组RAID5彼此构成条带访问
  - 在底层的任一组或多组RAID5中出现1颗硬盘损坏时, 仍能维持运作, 如果任一组RAID5中出现2颗或2颗以上硬盘损毁, 整组RAID50就会失效
  - RAID50由于在上层把多组RAID5进行条带化, 性能比起单纯的RAID5高, 但容量利用率比RAID5要低

#### RAID 6

![[../0_Attachment/image-20241126110535125.png]]

- 采用两种不同的校验码, 并将校验码以分开的块存于不同的磁盘中
- 优点: 提升数据可用性, 只有在平均修复时间间隔内3个磁盘都出了故障, 才会造成数据丢失
- 缺点: 写损失, 每次写都要影响两个校验块 (读3个写3个磁盘)

RAID 比较

- RAID 0: 提升I/O响应能力, 但数据可用性低
- RAID 1: 提升数据可用性, 但容量利用率低
- RAID 2 和 RAID3: 提升数据可用性和数据传输率, 但一次只能处理一个I/O请求
- RAID 4 和 RAID 5 和 RAID 6: 提升数据可用性和读速率, 但写速率受限

### PPT扩展

结构, 读写机制, 数据组织, 格式化, I/O访问时间, 磁头寻道

## 固态硬盘

SSD

### 原理

基于闪存技术 Flash Memory, 属于 EEPROM

### 组成

闪存翻译层: 负责翻译逻辑块号, 找到对应页(Page)

存储介质:多个闪存芯片 (Flash Chip) 

每个芯片包含多个**块** (block)

每个块包含多个**页** (page)

### 读写性能

以**页**为单位读/写--相当于磁盘的“扇区"

以**块**为单位"擦除", 擦干净的块, 其中的每页都可以写一次, 读无限次

支持随机访问

读快, 写慢. 要写的页如果有数据, 则不能写入, 需要将块内其他页全部复制到一个新的块中, 再写入新的页

### 相比机械硬盘

读写速度快, 随机访问性能高

安静无噪音, 耐摔抗震, 能耗低, 造价更贵

SSD的一个"块"被擦除次数过多(重复写同一个块)可能会坏掉, 机械硬盘不会

### 磨损均衡技术

动态磨损均衡 --写入数据时, 优先选择累计擦除次数少的新闪存块

SSD监测并自动进行数据分配, 迁移, 让老旧的闪存块承担以读静态磨损均衡为主的储存任务, 让较新的闪存块承担更多的写任务

## Cache

缓和CPU和主存的速度矛盾

### 局部性原理

空间局部性

在最近的未来使用的信息很可能与现在正在使用的信息在存储空间上是邻近的 (数组, 顺序执行的指令代码)

时间局部性

在最近的未来要用到的信息, 很可能是正在使用的信息 (循环结构的指令代码)

### 性能分析

命中率H

Cache-主存系统的平均访问时间为

-  $t = Ht_c + (1 - H)(t_c + t_m)$ (先访问cache) 
- $t = Ht_c + (1 - H) t_m$ (同时访问cache和主存)

### 一些问题

- 如何界定周围? 
  - 将主存的存储空间分块, 主存和cache之间以**块**为单位进行数据交换
  - 操作系统中主存的一个块也称为一个**页**/页面/页框
  - Cache的块也叫**行**
- 如何区分cache与主存的数据块对应关系?
  - cache和主存的映射方式
- cache满了怎么办?
  - 替换算法
- 如何保证数据一致性?
  - cache写策略

## Cache映射方式

给每个cache块增加一个标记, 记录对应的主存块号

有效位: 显示标记是否有效

### 全相联映射 Associative Mapping

随意放

标记长度: 与主存块号长度相同

访存: 取出目标地址的块号, 对比cache中所有块的标记, 若标记匹配且有效位为1, 则cache命中. 若未命中, 则正常访问主存.

优点: Cache存储空间利用充分, 命中率高

缺点: 查找“标记”最慢, 有可能需要对比所有行的标记

### 直接映射 Direct Mapping

只能放固定位置

主存块在cache中的位置 = 主存块号 % cache总块数

标记长度: 主存块号长度 - cache总块数长度

访存: 根据主存块号后x位确定cache行, 匹配该行标记...

优点: 对于任意一个地址, 只需对比一个"标记", 速度最快

缺点: Cache存储空间利用不充分, 命中率低

### 组相联映射 Set Associative Mapping

可放到特定分组的任意位置

n路组相联映射: 每n个cache行作为一组

所属分组 = 主存块号 % 分组数

标记长度: 主存块号长度 - 总分组数长度

访存: 根据主存块号的后x位确定所属分组号, 对比该分组内的cache所有块的标记...

是上面两种的折中

## Cache替换算法

全相联映射: Cache完全满了才需要替换需要在全局选择替换哪一块

直接映射: 由于映射位置固定, 毫无选择地直接替换 (没有算法)

组相联映射: 分组内满了才需要替换需要在分组内选择替换哪一块

### 随机算法 RAND

若Cache已满, 则随机选择一块替换.

实现简单, 但完全没考虑局部性原理, 命中率低, 实际效果很不稳定

### 先进先出算法 FIFO 

若cache已满, 则替换最先被调入的cache块

FIFO依然没考虑局部性原理, 最先被调入Cache的块也存可能是被频繁访问的

抖动现象: 频繁的换入换出现象, 刚被替换的块很快又被调入

### 近期最少使用算法 LRU

为每一个Cache块设置一个**计数器**, 用于记录每个Cache块已经有多久没被访问了. 当Cache满后替换计数最大的

- 命中时, 所命中的行的计数器清零, 比其低的计数器加1, 其余不变;
- 未命中且还有空闲行时, 新装入的行的计数器置0, 其余非空闲行全加1;
- 未命中且无空闲行时, 计数值最大的行的信息块被淘汰, 新装行的块的计数器置0, 其余全加1

对于有$2^n$行的cache, 计数器只需n位, cache装满后所有计数器的值一定不重复

基于局部性原理

### 最不经常使用算法 LFU

最为每一个Cache块设置一个**计数器,** 用于记录每个Cache块被访问过几次, 当Cache满后替换计数最小的.

新调入的块计数器=0, 之后每被访问一次计数器+1. 需要替换时, 选择计数器最小的一行.

多个最小: 行号递增, FIFO策略选择

没有很好地遵循局部性原理: 曾经被经常访问的主存块在未来不一定会用到

## Cache写策略

### 写命中

#### 写回法

当CPU对cache写命中时, 只修改cache的内容, 而不立即写入主存, 只有此块被换出时才写入主存, 未被修改的块不必写回

cache行脏位: 表示是否被修改过

存在数据不一致的隐患

#### 全写法

也叫写直通法 write-through 

当CPU对Cache写命中时, 必须把数据同时写入Cache和主存,

访存次数增加, 速度变慢, 但更能保证数据一致性

优化: 不写入主存而写入**写缓冲** (write buffer) (SRAM实现的FIFO队列, 在专门的控制电路控制下逐一写回主存)

提供CPU写速度, 但如果写操作很频繁, 会导致写缓冲饱和而发生阻塞

### 写不命中

#### 写分配法

当CPU对Cache写不命中时, 把主存中的块调入Cache, 在Cache中修改. 通常搭配写回法使用.

#### 非写分配法

当CPU对Cache写不命中时只写入主存, 不调入Cache. 搭配全写法使用

只有读未命中时才调入cache

### 多级Cache

- 现代计算机常采用多级Cache
- 离CPU越近的速度越快, 容量越小
- 离CPU越远的速度越慢, 容量越大
- 各级cache之间常采用全写法＋非写分配法 (数据一致性更好)
- cache主存直接常采用写回法 + 写分配法

## Cache行大小

- 假设从行的大小为一个字开始, 随着行大小的逐步增大, 则Cache命中率会增加
  - 数据块中包含了更多周围的数据, 每次会有更多的数据作为一个块装入cache中
  - 利用了空间局部性
- 当行大小变得较大之后, 继续增加行大小, 则Cache命中率会下降
  - 当Cache容量一定的前提下, 较大的行会导致Cache中的行数变少, 导致装入cache中的数据块数量减少, 进而造成数据块被频繁替换
  - 每个数据块中包含的数据在主存中位置变远, 被使用的可能性减小
- 行大小与命中率之间的关系较为复杂
  - 行太小, 行数太多反时间局部性
  - 行太大, 行数太少反空间局部性

## 虚拟存储器

*取COA课件11讲的思路, 覆盖王道网课"页式存储器"和"虚拟存储系统"两节的内容*

### 背景

#### 操作系统

第一台计算机诞生时

- 一个用户独占全机, 不会出现因资源已被其他用户占用而等待的现象, 但资源的利用率低
- CPU等待手工操作, 利用不充分

批处理系统

- 加载在计算机上的一个系统软件, 在它的控制下, 计算机能够自动地、成批地处理一个或多个用户的作业（包括程序、数据和命令）

操作系统

- 一种控制应用程序运行和在计算机用户与计算机硬件之间提供接口
  的程序
- 目标
  - 使计算机使用起来更方便
  - 允许计算机系统的资源以有效的方式使用

#### 存储器管理

- 早期计算机的主存中仅包含系统软件和一个用户程序
- 单道程序设计
- 现在计算机的主存中包含操作系统和若干个用户程序
  - 当所有任务都需要等待I/O时, 为了避免处理器处于空闲状态, 需要尽可能让更多的任务进入主存
  - 多道程序设计: 让处理器一次处理多个任务, 提高处理器的利用率
- 存储器管理
  - 在多道程序系统中, 主存需要进一步划分给多个任务, 划分的任务由操作系统动态执行
  - *本课不区分"进程"和"任务"这个更抽象的概念*

#### 问题: 如何将更多更大的任务装入主存?

- 增大主存容量
- 使用**交换 (exchange)技术**
  - 分区 (partitioning)
  - 分页 (paging)
- **虚拟存储器**

### 分区方式

将主存分为两大区域

- 系统区: 固定的地址范围内, 存放操作系统
- 用户区: 存放所有用户程序

#### 简单固定分区

- 用户区划分成长度不等的固定长的分区
- 当一个任务调入主存时, 分配一个可用的、能容纳它的、最小的分区
- 优点: 简单
- 缺点: 浪费主存空间
- ![[../0_Attachment/Pasted image 20241128173702.png]]

#### 可变长分区

- 用户区按每个任务所需要的内存大小进行分配
- 优点: 提高了主存的利用率
- 缺点: 时间越长, 存储器中的**碎片**就会越多
- ![[../0_Attachment/Pasted image 20241128173655.png]]

### 分页方式 (页式存储器)

背景

- 某一程序(进程)所需内存比较大, 很难在主存中找到连续的大段空间进行存放, 也会导致主存利用率不高.
- 减少分区方式中碎片的产生

基本思想

- 把主存分成固定长且比较小的存储块, 称为页框 (page frame), 每
  个任务也被划分成固定长的程序块, 称为页 (page)
- 将页装入页框中, 且无需采用连续的页框来存放一个任务中所有的页

逻辑地址: CPU指令的地址

物理地址: 实际主存地址

#### 页表

问题1: 如何实现物理地址和逻辑地址的转化? 使用**页表**.

- 页表存放在主存里, 通过页表基址寄存器确定页表在主存的位置 (查询页表即是一次访存操作)

- 页表记录了每个逻辑页号存放在哪个主存块中, 即将逻辑页号映射到主存块号

#### 快表

问题2: 每次访存都需要查页表, 相当于访存, 那cache不就没用了?

- 利用时间局部性原理 (在最近的未来中很有可能访问同一逻辑页), 参考cache的原理, 引入**快表** (TLB, Translation Lookaside Buffer). 
- 物理上使用SRAM实现, , 相联存储器, 可以按内容寻访
- 原来的页表也叫慢表, 快表存储的是慢表的一些表项的副本, 只有几个字节
- 区别: cache存储的是主存块中数据的副本, 比较大.
- 快表在**地址变换**的过程中起加速的作用; cache在**访存** (访问最终得到的**物理地址**) 的过程中起加速作用.
- 现在的计算机中, TLB和cache在物理上是两个存储器

### 虚拟存储器

背景: 内存的大小是有限的, 但对内存的需求不断增加

- 启动1gb的微信, 需要把全部内容调入主存吗? 
- 不需要, 调入部分即可.
- 多程序总大小远超内存却可以多开, 就是他们在启动时只把一部分内容调入主存
- 没有调入的部分, 在用到时再调入即可

基本思想: 请求分页

- 仅将当前需要的的页调入主存
- 通过硬件将逻辑地址转换为物理地址
- 未命中时在主存和硬盘之间交换信息

优点

- 在不扩大物理内存的前提下, 可以载入更多的任务
- 编写程序时不需要考虑可用物理内存的状态
  - 程序员认为可以独享一个连续的, 很大的内存
- 可以在大于物理内存的逻辑地址空间中编程

#### 页式虚拟存储器

主存储器和虚拟地址空间都被划分为大小相等的页面

- 虚拟页（virtualpage, VP）/逻辑页（logicalpage）：虚拟地址空间中的页面
- 物理页（physicalpage, PP）/页框（pageframe）：主存空间中的页面

改造页表

- 页表中包含了所有虚拟页的信息
- 虚拟页存放位置 (将虚拟页号映射到物理页号)
- **有效位 (valid)**: 表示该页是否有效 (被调入了主存)
- **脏位 (dirty)**: 标识该页的数据是否被更改
- **外存块号**: 让操作系统能找到并从磁盘调入未加载的页进主存
- **访问位**: 用来实现页面替换算法 (主存与辅存页面的替换, 操作系统内容)
- 虚拟地址: 虚拟页号 + 页内偏移量

CPU访存过程

![[../0_Attachment/Pasted image 20241128173628.png]]

TLB, 页表, cache的缺失组合

![[../0_Attachment/Pasted image 20241128173538.png]]

##### 多级页表

*来自 [知乎: 一文带你了解, 虚拟内存、内存分页、分段、段页式内存管理](https://zhuanlan.zhihu.com/p/451736494)*

简单的分页有空间上的缺陷.

- 每个进程维护一个拥有约100万 ($2^{20}$)个表项的页表, 占用约4MB; 若100个进程则占用约400MB, 非常占用内存.

解决: 多级页表, Multi-Level Page Table

- 新增一个页表指向这个含有100多万个表项的页表
- 如果没有访问到一级页表的表项, 就不需要创建二级页表
- 局部性原理

![[../0_Attachment/Pasted image 20241128233010.png]]

#### 段式虚拟存储器

将程序和数据分成不同长度的段, 将所需的段加载到主存中

此时主存不再分块, 段可以存放在主存的任意位置

虚拟地址:段号+段内偏移量

与分页式虚拟存储器相比

- 分页式虚拟存储器（页对程序员不可见）
  - 优点：实现简单、开销少
  - 缺点：一个数据或一条指令可能会分跨在两个页面
- 分段式虚拟存储器（段对程序员可见）
  - 优点：段的分界与程序的自然分界相对应, 易于编译、管理、修改和保护
  - 缺点：段的长度不固定（引起碎片）

段表

- 在主存中

- 段表基址寄存器存放着段表基地址

- 将段号映射到主存物理地址

- 有段号, 段首址 (段在主存中的起始地址), 装入位, 段长

#### 段页式虚拟存储器

把程序按逻辑结构分段, 每段再划分为固定大小的页

每个程序对应一个段表, 每段对应一个页表

虚拟地址: 段号 + 页号 + 页内偏移量

主存空间也划分为大小相等的页

程序对主存的调入, 调出仍以**页**为基本的传送单位

优点: 程序按段实现共享与保护

缺点: 需要多次查表