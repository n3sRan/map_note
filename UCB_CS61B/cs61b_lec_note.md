# UCB CS61B SP24

## Lecture Note

> è¿™é‡Œçš„ç¬”è®°æŒ‰ç…§ (é‡è¦) çŸ¥è¯†ç‚¹åˆ’åˆ†è€Œä¸æ˜¯è¯¾ç¨‹, å¯¹ä¸åŒéƒ¨åˆ†çš„çŸ¥è¯†ç‚¹ä½œäº†ä¸€ä¸ªç®€è¦çš„åˆ†å—

### Java Basic

#### The Golden Rule of Equals (and Parameter Passing)

- é™¤äº†å…«ç§åŸºæœ¬ç±»å‹å¤–, èµ‹å€¼/ä¼ å‚éƒ½æ˜¯å¤åˆ¶çš„å¼•ç”¨åœ°å€ (æŒ‡é’ˆ)

#### Nake Linked Lists vs. SLLists

- ä½¿ç”¨SLListséšè—é€’å½’çš„å®ç°ç»†èŠ‚

#### Sentinel Node

- å“¨å…µèŠ‚ç‚¹: ä¸€ä¸ªä¸€ç›´å­˜åœ¨çš„èŠ‚ç‚¹, ç»Ÿä¸€Listså…§æ–¹æ³•çš„å®ç° (ä¸ç”¨ä¸ºäº†ç‰¹æ®Šæƒ…å†µå†å†™ä¸€ä»½ç›¸è¿‘çš„ä»£ç , ä»è€Œå®ç°ä»£ç çš„ç²¾ç®€)
- DLList: åŒå‘é“¾è¡¨, å¯ä»¥åœ¨é¦–å°¾å‡æ”¾ç½®ä¸€ä¸ªsentinel, ä¹Ÿå¯ä»¥åªä½¿ç”¨ä¸€ä¸ªä½¿å¾—é“¾è¡¨å½¢æˆç¯ (å½“è¿­ä»£åˆ°sentinelæ—¶è¯´æ˜åˆ°è¾¾é“¾è¡¨ç»“å°¾)

#### Arrays vs. Classes

- Javaå…è®¸åœ¨è¿è¡Œæ—¶è¯„ä¼°æ•°ç»„ç´¢å¼•
- ç±»æˆå‘˜å˜é‡å (class member variable name) åœ¨è¿è¡Œæ—¶ä¸èƒ½è¢«è®¡ç®—å’Œä½¿ç”¨ (computed and used), the only (easy) way to access a member of a class is with hard-coded dot notation
- æ›´å¤šç»†èŠ‚è¯·å‚è€ƒæ“ä½œç³»ç»Ÿè¯¾ç¨‹ (or cs61c)

#### Interface vs. Implementation Inheritance

- Interface Inheritance (what): æ¥å£ç»§æ‰¿, åˆ—å‡ºéœ€è¦å®ç°çš„æ–¹æ³• (ç­¾å)
- Implementation Inheritance (how): å…è®¸ä»£ç å¤ç”¨, å­ç±»å¯ä½¿ç”¨çˆ¶ç±»/æ¥å£çš„æ–¹æ³•(ä¹Ÿå¯è‡ªè¡Œå†³å®šèƒ½å¦è¦†å†™) (Example: print() method in 61BList.java)

#### Constructor Behavior ls Slightly Weird

- Constructors are not inherited. However, the rules of Java say that all constructorsmust start with a call to one of the super class's constructors Link. 
- Javaä¼šåœ¨è°ƒç”¨æ„é€ å‡½æ•°æ—¶è‡ªåŠ¨**å…ˆ**è°ƒç”¨å…¶ (å³ä½¿æ²¡æœ‰å†™super()ä¹Ÿä¼šéšå¼è°ƒç”¨**æ²¡æœ‰å‚æ•°**çš„) çˆ¶ç±»çš„æ„é€ å‡½æ•°

#### Compile-Time (Static) Types vs. Run-Time (Dynamic) Types

- **Compile-Time Type Checking**: 

  - Compiler allows method calls based on compile-time type of variable

  - Compiler also allows assignments based on complie-time types

  - ```java
    public static void main(String[] args){
    	VengefulSLList<Integer>vsl = new VengefulSLList<Integer>(9);
        SLList<Integer>sl=vsl;
        
        sl.addLast(50);
        sl.removeLast();
        
        sl.printLostItems(); //Compilation errors!
        VengefulSLList<Integer>vsl2 = sl; //Compilation errors!
    }
    ```

- **Expressions have compile-time types** 

  - ```java
    SLList<Integer>sl = new VengefulsLList<Integer>(9); //OK!
    VengefulsLList<Integer>vsl = new SLLlist<Integer>(9); //Compilation errors!
    ```

- **Casting**: å¼ºåˆ¶ç±»å‹è½¬æ¢, é˜²æ­¢ç¼–è¯‘å™¨æŠ¥é”™ (æœ‰é£é™©)

#### is-a vs. has-a

- Stack æ ˆ
  - åªæœ‰popå’Œpushæ“ä½œ
  - å¦‚æœis-a List, åˆ™ç»§æ‰¿äº†Listçš„æ‰€æœ‰æ–¹æ³•å¦‚get, addfirstç­‰ä¸åº”è¯¥æœ‰çš„åŠŸèƒ½, Ã—
  - å¦‚æœhas-a List, åˆ™å¯ä»¥ä½¿ç”¨ä¸€ä¸ªList(private)æ¥å­˜å‚¨æ•°æ®, åªæœ‰pop (removeLast) å’Œpush (addLast) åŠŸèƒ½ âˆš

#### Subtype Polymorphism

- **Polymorphism**: providing a single interface to entities (å®ä½“å¯¹è±¡) of different types
- **Explicit Higher Order Functions vs. Subtype Polymorphism**:
  - å‰è€…: æ˜¾å¼ä¼ é€’é«˜é˜¶å‡½æ•° (e.g. Python) `def print_larger(x, y, compare, stringfy)`
  - åè€… "let the **object** do all the thinking for us"
- Example: ç¼–å†™è¾“å‡ºå¤šä¸ªå¯¹è±¡çš„maxçš„å‡½æ•°, å¤šæ€çš„æ€æƒ³æ˜¯æä¾›ä¸€ä¸ªæ¥å£Comparableè®©æ¯ä¸ªå¯æ¯”è¾ƒå¯¹è±¡ç»§æ‰¿compareToæ–¹æ³•, å†å†™ä¸€ä¸ªç»Ÿä¸€çš„maxå‡½æ•°, è€Œä¸æ˜¯ç»™æ¯ç§å¯¹è±¡ç¼–å†™ä¸€ä¸ªæ¯”è¾ƒå…¶å…·ä½“å†…å®¹ (field) çš„å‡½æ•° (e.g. maxDog: dog.size, maxRuler: ruler.length)

#### Comparable Advantages

- Implementing Comparable allows library functions to compare custom types (e.g. finding max).

#### Comparator

- æ¯”è¾ƒå™¨, æ˜¯ä¸€ä¸ªç±»çš„ä»å±åŠŸèƒ½ (é™æ€åµŒå¥—ç±»)
- a dog comparator is **not** a dog (ä¹Ÿå°±è¯´æ˜å¯ä»¥æŠŠæ¯”è¾ƒå™¨å†™åœ¨ç±»ä¹‹å¤–, è¿™åœ¨é€»è¾‘ä¸Šæ²¡æœ‰åŒºåˆ«)

#### For-each Iteration And ArraySets

- ArraySet **is** Iterable and **has a** Iterator

### Data Structure

#### Analysis of Algorithm Performance

- Asymptotic: æ¸è¿›åˆ†æ, å½“Nè¶³å¤Ÿå¤§æ—¶, æ—¶é—´å¢é•¿é€Ÿç‡ä¸Nå¢é•¿é€Ÿç‡å‘ˆä»€ä¹ˆå…³ç³»
- Amortized: æ‘Šé”€åˆ†æ, å•ä¸ªæ“ä½œå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´, ä½†å¦‚æœè¿›è¡Œå¤šæ¬¡æ“ä½œ, å¯ä»¥æ‹¥æœ‰æ›´å¥½çš„å¹³å‡æ€§èƒ½
  - å¯è°ƒæ•´æ•°ç»„å¤§å°çš„ArrayList (ä¹‹å‰çš„Labå®ç°), åªæœ‰åœ¨æ•°ç»„æ»¡äº†æ‰ç¿»å€resize, resizeçš„æ—¶é—´ä¸åŸæ•°ç»„å¤§å°å‘ˆçº¿æ€§, åˆ™Næ¬¡addLastæ“ä½œæ¶ˆè€—æ€»æ—¶é—´ä¸º (N (æ¯æ¬¡æ™®é€šaddæ“ä½œçš„å¸¸æ•°æ—¶é—´) + 1 + 2 + 4 + 8 ... +N (resizeçš„æ€»æ—¶é—´)), å³Î˜(N), æ‘Šé”€åaddLastæ“ä½œä¸ºÎ˜(1). 
  - WQU Disjoint sets with path compression
- Recursive: é€’å½’åˆ†æ (e.g. æ–æ³¢é‚£å¥‘æ•°åˆ—)
- Remember: no magic shortcuts!

#### ADTs

- Abstract Data Type: æŠ½è±¡æ•°æ®ç±»å‹, å¯ä»¥ç†è§£ä¸ºæä¾›æ¥å£, ä½†å¯ä»¥æœ‰ä¸åŒå®ç°.
- è¯¾ä¸Šå·²å®ç°çš„: List
- éœ€è¦å»å®ç°çš„: Set, Map (ç›¸å…³ä»£ç å¯å‚è€ƒLabçš„å®ç°)

#### BST

- Binary Search Tree äºŒå‰æœç´¢æ ‘
- æˆ‘ä»¬ä½¿ç”¨ Set/Map æ—¶ä¸éœ€è¦è€ƒè™‘å…¶ä¸­çš„é¡ºåº (ADTè§„å®š), ä½†ADTæ¥å£çš„ä¸åŒå®ç°ä¼šå½±å“æ€§èƒ½/æ•ˆç‡
- ç±»æ¯”äºŒåˆ†æŸ¥æ‰¾: æœç´¢BSTä¸­æ•°æ®æ—¶, ç›®æ ‡å€¼ç­‰äºå½“å‰å€¼, è¿”å›; å°äº, æœç´¢å·¦æ ‘; å¤§äº, æœç´¢å³æ ‘.
- å¦‚æœæ˜¯éšæœºç”Ÿæˆçš„BST, é‚£ä¹ˆæ—¶é—´å¤æ‚åº¦ä¸º$O(\log {n})$, ä½†BSTåœ¨æç«¯æƒ…å†µä¸‹æ—¶é—´å¤æ‚åº¦ä¼šæ¥åˆ°$O(n)$ (e.g.ä»1ä¸€ç›´åŠ åˆ°N)

#### B-Trees

- å¯¹BSTçš„ä¼˜åŒ–
- ä¸å…è®¸æ–°å¢å¶, ä½†å…è®¸ä¸€ä¸ªèŠ‚ç‚¹å­˜æ”¾æœ€å¤šLä¸ªæ•°æ®, å½“æ•°æ®å¤šäºLæ—¶, èŠ‚ç‚¹å‘ä¸Šä»¥åŠæ—è¾¹åˆ†è£‚, æ ¹èŠ‚ç‚¹å‘ä¸Šåˆ†è£‚æ—¶, ç›¸å½“äºå…¨éƒ¨èŠ‚ç‚¹å‘ä¸‹ç§»ä¸€å±‚, ä¿è¯äº†å¶çš„æ·±åº¦ä¸€è‡´ä»¥åŠæ ‘çš„å¹³è¡¡, (ç›¸å½“äºä»ä¸‹è€Œä¸Šæ„å»ºæ ‘), ä¿è¯äº†æ ‘çš„ç›¸å…³æ“ä½œä¸º$O(\log {n})$.
- Invariants ä¸å˜æ€§: 
  - All leaves must be the same distance from the source.
  - A non-leaf node with ğ‘˜ items must have exactly ğ‘˜+1 children.
- ç¼ºç‚¹: åœ¨ä»£ç ä¸Šæ¯”è¾ƒéš¾å®ç°

#### Rotating Trees

- å‰ç½®: æ ‘çš„æ—‹è½¬
- rotateLeft(G): Let x be the right child of G. Make G the new left child of x.
  rotateRight(G): Let x be the left child of G. Make G the new right child of x.
- å¯ä»¥å°†æ—‹è½¬çš„è¿‡ç¨‹è§†ä½œå…ˆå°†ä¸¤ä¸ªç»“ç‚¹åˆå¹¶, å†å°†åŸç»“ç‚¹ "å‘å°„" åˆ°å¦ä¸€ä¾§çš„è¿‡ç¨‹

#### RBT

- Red-Black Trees çº¢é»‘æ ‘
- é€šè¿‡åˆ©ç”¨æ ‘çš„æ—‹è½¬, ä½¿ç”¨ BST çš„ç»“æ„æ¥æ¨¡æ‹Ÿ B æ ‘ (åŒæ„), å®ç°ä»£ç çš„ç®€æ´, åŒæ—¶ä¿è¯æ•ˆç‡ä¸æ€§èƒ½
- è¯¾å ‚ä¸Šä»¥åŠå®éªŒä¸­ä½¿ç”¨çš„æ˜¯ **LLRB** å·¦å€¾çº¢é»‘æ ‘

#### Hashing

- å“ˆå¸Œè¡¨
- ç”¨ç©ºé—´æ¢æ—¶é—´, å°†Nä¸ªå…ƒç´ æ”¾è¿›Mä¸ªç›’å­é‡Œ, MéšNå¢é•¿, ä½¿å¾—æ—¶é—´å¤æ‚åº¦ä¸º$O(M/N)$, å³$O(1)$. (æ‘Šé”€åˆ†æ)

#### PQ

- Priority Queue: ä¼˜å…ˆçº§é˜Ÿåˆ—, ä¸€ç§æŠ½è±¡æ•°æ®ç±»å‹, å¯ä»¥æ·»åŠ å…ƒç´ , ä½†åªèƒ½è®¿é—®/åˆ é™¤æœ€å°/æœ€å¤§çš„å…ƒç´ 
- å¯èƒ½çš„å®ç°:
  - Ordered Array: `add`: Î˜(ğ‘) `getSmallest`: Î˜(1) `removeSmallest`: Î˜(ğ‘)
  - Bushy BST: `add`: Î˜(logğ‘) `getSmallest`: Î˜(logğ‘) `removeSmalles`t: Î˜(logğ‘), ä½†æ˜¯ä¸èƒ½æœ‰é‡å¤çš„å…ƒç´ 
  - HashTable: `add`: Î˜(1) `getSmallest`: Î˜(ğ‘) `removeSmallest`: Î˜(ğ‘)
- æ›´å¥½çš„å®ç°: **äºŒå‰å †**

#### Heap

- å †: ä¸€é¢—**å®Œæ•´çš„**äºŒå‰æ ‘, æ¯ä¸ªç»“ç‚¹çš„å€¼**å°äºç­‰äº**å…¶ä¸¤ä¸ªå­èŠ‚ç‚¹çš„å€¼, æ‰€æœ‰ç»“ç‚¹å°½é‡**å·¦å€¾**
- ä½¿ç”¨Heapå®ç°PQ
  - `getSmallest`: Î˜(1).
  - `add`: Add to the end of heap temporarily. Swim up the hierarchy to the proper place. åŠ åˆ°åº•, å¾€ä¸Šæµ® (äº¤æ¢). Î˜(logğ‘).
  - `removeSmallest`: Swap the last item in the heap into the root. Sink down the hierarchy to the proper place. å°†åº•éƒ¨çš„æ›¿æ¢é¡¶éƒ¨, å¾€ä¸‹æ²‰ (äº¤æ¢). Î˜(logğ‘)
  - è¡¥å……: ç›¸æ¯”BST, æ”¯æŒé‡å¤é¡¹

####  Tree Traversal

- Level Order Traversal å±‚åº: é€å±‚éå†
- Pre-order Traversal å‰åº: å…ˆéå†è‡ªèº«, å†å·¦æ ‘, å†å³æ ‘
- In-order Traversal ä¸­åº: å…ˆéå†å·¦æ ‘, å†è‡ªèº«, å†å³æ ‘
- Post-order Traserval ååº: å…ˆéå†å·¦æ ‘, å†å³æ ‘, å†è‡ªèº«
- è¡¥å……: è¿™é‡Œçš„ "å‰, ä¸­, å³" æ˜¯é’ˆå¯¹è‡ªèº«èŠ‚ç‚¹è€Œè¨€

#### Graph

- å›¾: A graph consists of:
  - A set of nodes (or vertices).
  - A set of zero of more edges, each of which connects two nodes.
- Basic Problems
- DFS: Depth First Search æ·±åº¦ä¼˜å…ˆæœç´¢.
- BFS: Breadth First Search å¹¿åº¦ä¼˜å…ˆæœç´¢.

#### Shortest Paths

- æœ€çŸ­è·¯å¾„é—®é¢˜
- å¯¹äºéåŠ æƒå›¾, BFSåœ¨æœç´¢å®Œæˆåå³ç­‰åŒäºè§£å†³äº†æœ€çŸ­è·¯å¾„é—®é¢˜
- å¯¹äºåŠ æƒå›¾
  - åŸå§‹äººæ“ä½œ: åœ¨æƒé‡ä¸ºkçš„è¾¹ä¸Šæ·»åŠ k-1ä¸ªè™šæ‹ŸèŠ‚ç‚¹, ç„¶åä½¿ç”¨BFS, ä½†è¿™ä¼šå½±å“æ•ˆç‡
  - **Dijkstra**:
    1. åˆ›å»ºä¸€ä¸ª PQ, å…¶å†…å®¹å³ä¸ºå„ä¸ªé¡¶ç‚¹, å¯¹åº”çš„å€¼æ—¶å½“å‰æ—¶åˆ»æ¯ä¸ªé¡¶ç‚¹åˆ°æºé¡¶ç‚¹çš„æœ€çŸ­è·ç¦»
    2. å°†åˆå§‹ç‚¹çš„å€¼è®¾ä¸º0, å…¶ä»–çš„è®¾ç½®ä¸ºæ­£æ— ç©·
    3. å½“ PQ éç©ºæ—¶, å¼¹å‡ºå…¶é¡¶ç‚¹, å¹¶**relax**å…¶æ‰€æœ‰è¾¹, ç›´åˆ° PQ ä¸ºç©º. Relax: æ£€æŸ¥å½“å‰é¡¶ç‚¹xçš„æ‰€æœ‰è¾¹e, å¦‚æœxçš„è·ç¦»åŠ ä¸Šè¯¥è¾¹çš„æƒé‡å°äºeçš„å¦ä¸€ä¸ªé¡¶ç‚¹yçš„è·ç¦», åˆ™æ›´æ–°y. (å¼¹å‡ºé¡¶ç‚¹çš„è¿‡ç¨‹å¯ä»¥å°†é¡¶ç‚¹æ ‡è®°, è¿™æ„å‘³è¿™relaxè¿‡ç¨‹ä¸­å¯ä»¥ä¸è®¿é—®è¢«æ ‡è®°è¿‡çš„é¡¶ç‚¹, å› ä¸ºè¿™äº›é¡¶ç‚¹å·²ç»æ‰¾åˆ°äº†æœ€çŸ­è·ç¦».)
    4. å±€é™æ€§: è¾¹çš„æƒé‡å¿…é¡»éè´Ÿ
  - **A***: Dç®—æ³•ç±»ä¼¼äºåŒå¿ƒåœ†ä¸€èˆ¬çš„æœç´¢, ä½†å¦‚æœæˆ‘åªæƒ³çŸ¥é“ä¸¤ç‚¹é—´çš„æœ€çŸ­è·¯å¾„å‘¢? æ¯”å¦‚å¹¿å·åˆ°å—äº¬çš„æœ€çŸ­è·¯å¾„, æˆ‘åœ¨Dç®—æ³•æ—¶å®é™…ä¸Šä¹Ÿæœç´¢äº†å¹¿å·åˆ°æµ·å—çš„æœ€çŸ­è·¯å¾„, ä½†è¿™æ˜¯æˆ‘ä¸éœ€è¦çš„, è¿™æ„å‘³è¿™å³ä½¿æµ·å—ç¦»å¹¿å·æ›´è¿‘, ä½†æˆ‘ä¸æƒ³è®¿é—® (ä»PQä¸­å¼¹å‡º) è¿™ä¸€ä¸ªé¡¶ç‚¹, è¿™éœ€è¦ç»™PQçš„æ’åˆ—åŠ ä¸€ç‚¹æ–¹å‘æ€§, å³æ ¹æ®ä¸€ä¸ªå·²çŸ¥çš„è¡¨æ¥ç»™PQä¸­æ¯ä¸ªç‚¹è·ç¦»æ–½åŠ ä¸€ç‚¹"æƒ©ç½š", ä¾‹å¦‚åœ¨æ¢ç´¢ "å¹¿å·åˆ°å—äº¬çš„æœ€çŸ­è·¯å¾„" çš„è¡¨ä¸­æˆ‘ç»™æ¯ä¸ªç‚¹åšä¸€ä¸ª "æƒ©ç½š" é¢„ä¼°è®¡, ç»™æµ·å—çš„è·ç¦»æ·»åŠ âˆçš„æƒ©ç½š, è¿™ä¿è¯äº†æˆ‘åœ¨å¼¹å‡ºå—äº¬å‰ä¸ä¼šå…ˆå¼¹å‡ºæµ·å— (å¼¹å‡ºå—äº¬è¯´æ˜æœç´¢ç»“æŸ), æå‡äº†æ•ˆç‡. ä½†å¦‚æœè¿™å¼ è¡¨ä¸å¤Ÿå¥½, åˆ™ç®—æ³•çš„æ­£ç¡®æ€§ä¼šå—åˆ°å½±å“, æ¯”å¦‚ä¹‹å‰çš„æœ€çŸ­è·¯å¾„ä¸€å®šä¼šåŒ…å«æ­¦æ±‰, ä½†æ˜¯å¦‚æœæˆ‘ä»¬ç»™æ­¦æ±‰èµ‹äºˆè¾ƒå¤§çš„æƒ©ç½š, åˆ™A*ç®—æ³•å¾—å‡ºçš„æœ€çŸ­è·¯å¾„å¯èƒ½ä¸ç»è¿‡æ­¦æ±‰, ä¸æ­£ç¡®ç­”æ¡ˆåç¦»äº†.

#### MST

- Minimum Spanning Trees æœ€å°ç”Ÿæˆæ ‘: åŒ…å«äº†å›¾ä¸­æ‰€æœ‰ç»“ç‚¹çš„ä¸”æ€»æƒé‡å’Œæœ€çŸ­çš„ä¸€æ£µæ ‘
- Cut åˆ‡å‰²: ç»™å®šä»»ä½•åˆ‡å‰², æœ€å°æƒé‡çš„æ¨ªè·¨è¾¹åœ¨æœ€å°ç”Ÿæˆæ ‘ä¸­
- **Primâ€™s Algorithm**: ç±»ä¼¼ Dijkstra ç®—æ³•, åªæ˜¯å°†åˆ°æºé¡¶ç‚¹çš„è·ç¦»æ¢æˆåˆ°å½“å‰æ ‘çš„è·ç¦»
  1. Start from some arbitrary start node.
  2. Repeatedly add the shortest edge that has one node inside the MST under construction.
  3. Repeat until there are V-1 edges.
- **Kruskalâ€™s Algorithm**:
  1. Sort all the edges from lightest to heaviest.
  2. Taking one edge at a time (in sorted order), add it to our MST under construction if doing so does not introduce a cycle.
  3. Repeat until there are V-1 edges.

#### Topological Sorts

- æ‹“æ‰‘æ’åº: å¯¹å›¾çš„é¡¶ç‚¹è¿›è¡Œæ’åº, ä½¿å¾—å¯¹äºæ¯ä¸€æ¡æœ‰å‘è¾¹ uâ†’v, uæ’åºåœ¨vä¹‹å‰
- ç®—æ³•å®ç°: å¯¹äºæ‰€æœ‰å…¥åº¦ä¸º0çš„èŠ‚ç‚¹
  1. Perform a DFS traversal from every vertex in the graph, **not** clearing markings in between traversals.
  2. Record DFS postorder along the way.
  3. Topological ordering is the reverse of the postorder.

#### DAGs

- Directed Acyclic Graphs æœ‰å‘æ— ç¯å›¾
- æ‹“æ‰‘æ’åºçš„é€‚ç”¨èŒƒå›´

#### Shortest Path Algorithm for DAGs

- å½“DAGsä¸­å­˜åœ¨è´Ÿæƒè¾¹æ—¶, Dijkstraç®—æ³•å¯èƒ½å¤±è´¥, å¦‚ä½•è§„é¿?
- å¤±è´¥åŸå› : åœ¨ä¸€ä¸ªé¡¶ç‚¹aä¸Šrelaxå®ƒçš„è¾¹æ—¶, å¦‚æœå­˜åœ¨è´Ÿæƒè¾¹æŒ‡å‘å·²ç»è¢«æ ‡è®°çš„é¡¶ç‚¹b, ä¸”bå› ä¸ºè·ç¦»å˜å°éœ€è¦è¢«æ›´æ–°, æ­¤æ—¶Dç®—æ³•å¹¶ä¸ä¼šæ›´æ–°, å› æ­¤å¤±æ•ˆ;
- è§£å†³: å…ˆæ‹“æ‰‘æ’åº, å†æŒ‰æ’åºç»“æœé€ä¸ªè®¿é—®èŠ‚ç‚¹å¹¶relaxå…¶è¾¹, å³ä¿è¯äº†relaxè¾¹æ—¶ä¸ä¼šè®¿é—®åˆ° (ä¹Ÿä¸å¯èƒ½) å·²ç»è¢«æ ‡è®°çš„èŠ‚ç‚¹ (æ‰€æœ‰è¾¹éƒ½æŒ‡å‘ä¸€ä¸ªæ–¹å‘).

#### Longest Paths

- å¦‚ä½•æ±‚æ— ç¯æœ€é•¿è·¯å¾„? æŒ‡æ•°æ—¶é—´å¤æ‚åº¦ (æ— æ³•åº”ç”¨, ç­‰äºæ— è§£)
- å¦‚æœæ˜¯DAGå‘¢?
  - Preprocess: å°†æ‰€æœ‰è¾¹å–è´Ÿ
  - æ±‚æœ€çŸ­è·¯å¾„
  - Postprocess: å°†è·¯å¾„ä¸Šçš„è¾¹å–è´Ÿ

#### Reductions

- (å½’åŒ–?) ç”¨ SPT-DAG çš„æ–¹æ³•æ¥è§£å†³ LPT-DAG é—®é¢˜, ä¾¿æ˜¯ä¸€ç§ reduction çš„ç­–ç•¥ (DAG-LPT reduces to DAG-SPT.)

#### Tries

- å­—å…¸æ ‘ (æ£€ç´¢æ•°): å­—ç¬¦ä¸²(å³ç”± ASCII ç æ„æˆ)çš„æ£€ç´¢æ•°æ®ç»“æ„, åœ¨è·å–å•è¯ã€æ·»åŠ å•è¯å’Œä¸€äº›ç‰¹æ®Šå­—ç¬¦ä¸²æ“ä½œæ–¹é¢å…·æœ‰å‡ºè‰²çš„æ€§èƒ½. æ¯”å¦‚å¯»æ‰¾æ‰€æœ‰ä»¥saå¼€å¤´çš„å•è¯, é€Ÿåº¦ä¼šæ¯”äºŒå‰æ ‘/å“ˆå¸Œè¡¨å¿«å¾—å¤š
- å¦‚ä½•è¡¨ç¤ºå­—ç¬¦ä¸²çš„ç»“å°¾ (å³æ ‘ä¸­å«æœ‰è¿™ä¸ªå­—ç¬¦ä¸²)? 
  - å°†æ¯ä¸ªå­—ç¬¦ä¸²çš„æœ€åä¸€ä¸ªå­—ç¬¦æ ‡è®° (æ¶‚æˆè“è‰²).
- æ—¶é—´å¤æ‚åº¦: Î˜(1).

### Algorithm

#### Selection Sort

- é€‰æ‹©æ’åº: ä¾æ¬¡å¯»æ‰¾æœªæ’åºçš„æ•°ç»„ä¸­çš„æœ€å°å€¼æ”¾åœ¨å·²æ’åºæ•°ç»„çš„æœ€å
- æ—¶é—´å¤æ‚åº¦: $Î˜(N^2)$ ç©ºé—´å¤æ‚åº¦: $Î˜(1)$.

#### Heapsort

- å †æ’åº: æ„é€ ä¸€ä¸ªå †å¹¶ä¾æ¬¡å–å‡ºé¡¶éƒ¨å…ƒç´ 
- **Naive Heapsort**: æœ´ç´ å †æ’åº
  1. Insert all items into a max heap, and discard input array. Create output array.
  2. Repeat N times:
     - Delete largest item from the max heap.
     - Put largest item at the end of the unused part of the output array.
  3. æ—¶é—´å¤æ‚åº¦: $Î˜(N \log N)$ ç©ºé—´å¤æ‚åº¦: $Î˜(N)$.
- **In-Place Heapsort**: åŸåœ°å †æ’åº
  1. Rather than inserting into a new array of length N + 1, use a process known as â€œbottom-up heapificationâ€ to convert the array into a heap.
  2. Repeat N times: Delete largest item from the max heap, swapping root with last item in the heap.
  3. æ—¶é—´å¤æ‚åº¦: $Î˜(N \log N)$ ç©ºé—´å¤æ‚åº¦: $Î˜(1)$**. (Bad cache (61C) performance)

#### Mergesort

- å½’å¹¶æ’åº: å°†æ•°ç»„ä¸€åˆ†ä¸ºäºŒ, åˆ†åˆ«è¿›è¡Œå½’å¹¶æ’åº (é€’å½’), å†åˆå¹¶. (æ•°ç»„é•¿åº¦ä¸º1æ—¶ä¸éœ€æ’åºåªéœ€åˆå¹¶)
- æ—¶é—´å¤æ‚åº¦: $Î˜(N \log N)$ ç©ºé—´å¤æ‚åº¦: $Î˜(N)$. (æ¯”å †æ’åºå¿«)

#### Insertion Sort

- æ’å…¥æ’åº: ä¾æ¬¡å°†æœªæ’åºæ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ æ’å…¥åˆ°å·²æ’åºçš„æ•°ç»„ä¸­.
- æ—¶é—´å¤æ‚åº¦: $Î˜(N^2)$
- **Naive Insertion Sort** æœ´ç´ æ’å…¥æ’åº
  - Starting with an empty **output** sequence.
  - Add each item from **input**, inserting into **output** at right point.
  - ç©ºé—´å¤æ‚åº¦: $Î˜(N)$
- **In-Place Insertion Sort**
  - Do everything in place using swapping.
  - ç©ºé—´å¤æ‚åº¦: $Î˜(1)$.
- Best for small N or almost sorted. å¯¹äºä¸€äº›åªæœ‰è¾ƒå°‘ä¹±åºå…ƒç´ çš„æ•°ç»„/é•¿åº¦è¾ƒå°çš„æ•°ç»„, æ’å…¥æ’åºä¼šå¾ˆå¿«
- Java: å½’å¹¶æ’åºæ—¶åˆ†å‰²åˆ°è¾ƒå°éƒ¨åˆ†å°±ä½¿ç”¨æ’å…¥æ’åº

#### Quciksort

- å¿«é€Ÿæ’åº: ä»»é€‰ä¸€ä¸ªåŸºå‡†å€¼, å°†å°äºåŸºå‡†å€¼çš„æ•°æ”¾åœ¨å·¦è¾¹, å¤§äºç­‰äºåŸºå‡†å€¼çš„æ•°æ”¾åœ¨å³è¾¹, **åˆ†åŒº**åè¯¥åŸºå‡†å€¼ä½äºæ­£ç¡®çš„ä½ç½®, ç„¶ååœ¨åˆ†åˆ«å¯¹ä¸¤è¾¹è¿›è¡Œå¿«é€Ÿæ’åº.
- æ—¶é—´å¤æ‚åº¦: 
  - best case: $Î˜(N \log N)$
  - worst case: $Î˜(N^2)$
  - Randomly chosen array case: $Î˜(N \log N)$
- ç©ºé—´å¤æ‚åº¦: $Î˜(\log N)$ (è°ƒç”¨æ ˆ)
- Hoare Partitioning: å°†ç©ºé—´å¤æ‚åº¦é™ä¸º $Î˜(1)$
  1. Create L and G pointers at left and right ends.
  2. L pointer is a friend to small items, and hates large or equal items. G pointer is a friend to large items, and hates small or equal items.
  3. Walk pointers towards each other, stopping on a hated item. When both pointers have stopped, swap and move pointers by one.
  4. When pointers cross, you are done.
- Quick Select: ç”¨äºå¯»æ‰¾ä¸­ä½æ•°åŸºå‡†å€¼, æ—¶é—´å¤æ‚åº¦: $Î˜(N)$
- è¿˜æœ‰ä¸€äº›é¿å…worst caseçš„å†…å®¹è¿™é‡Œå°±ä¸å†™äº†, ä½œç”¨ä¸å¤§.

#### Comparison Sorts

- ä»¥ä¸Šå‡æ˜¯
- æœ‰ä»€ä¹ˆä¸æ˜¯comparison sortçš„å‘¢?
  - Radix Sort, Sleepsort, Gravity Sort, BOGOsort

#### Theoretical Bounds on Sorting

- é€‚ç”¨äºcomparison sort
- å‰æ: $Î˜(N \log N) = Î˜(N!)$
- æ’åºçš„ç»“æœæœ‰$N!$ç§, å¯¹äºæ¯”è¾ƒæ³•è¿™ä¸€**å†³ç­–æ ‘**è€Œè¨€éœ€è¦æœ‰$\log (N!)$å±‚, è¿™å†³å®šäº†æ¯”è¾ƒæ’åºæ³•æ—¶é—´å¤æ‚åº¦çš„ä¸‹é™ä¸º$Î˜(N \log N)$

#### Sorting Stability

- A sort is said to be stable if order of equivalent items is preserved.
- Insertion sort: stable é‡åˆ°ç›¸ç­‰å°±åœäº†
- Mergesort: stable
- Quicksort: Depends on your partitioning strategy. é¢‘ç¹äº¤æ¢: unstable, éå†æ³•: stable.
- Heapsort: unstable

#### Radix Sort

- åŸºæ•°æ’åº: è¯¾ä¸Šä» Digit-by-digit Sorting å’Œ Counting Sort è¿‡æ¸¡è¿‡æ¥. 
- **Counting Sort**
  - Alphabet keys only
  - å…ˆéå†ä¸€éæ•°ç»„, ç»™æ¯ç§ç›¸åŒçš„æ•°åˆ†ä¸€ä¸ªåŒº (æŒ‡å®šèµ·å§‹ä¸‹æ ‡), å†éå†åŸæ•°ç»„æŒ‰ç…§èµ·å§‹ä¸‹æ ‡å¡«å…¥æ–°æ•°ç»„
  - æ—¶é—´å¤æ‚åº¦: $Î˜(N + R)$
- **LSD Radix Sort**
  - Strings of alphabetical keys only
  - ä»ä½ä½åˆ°é«˜ä½è¿›è¡Œéå†åˆ†ç»„ (10ç»„), ç”±äºCounting Sortæ˜¯ç¨³å®šçš„, éå†å®Œæˆåæ’åºå®Œæˆ
  - æ—¶é—´å¤æ‚åº¦: $Î˜(WN + WR)$ (ä¿è¯äº†Rå¾ˆå°)
- **MSD Radix Sort**
  - éå†æœ€é«˜ä½è¿›è¡Œåˆ†ç»„, å†åœ¨å„åˆ†ç»„**ç»„å†…**å°†å‰©ä½™ä½è¿›è¡ŒMSD Radix Sort.
  - æ—¶é—´å¤æ‚åº¦: 
    - best: $Î˜(N + R)$ 
    - worst: $Î˜(WN + WR)$ 

### Extension

#### Compression

- ç†è®ºä¾æ®: Shannon Entropy é¦™å†œç†µ
- ä»‹ç»äº†å‡ ç§å‹ç¼©æ–‡æœ¬çš„ç¼–ç æ–¹æ³•
  - Prefix Free Codes
  - Shannon Fano Codes
  - Huffman Coding
    - Build one corpus per input type.
    - For every possible input file, create a unique code just for that file. Send the code along with the compressed file. (æ›´å¸¸ç”¨)

#### Turing Machine

- In general, we can find a reduction from a function problem (ex. What should I steal) to a decision problem (ex. Can you steal at least this much?)
- Formally, any decision problem in theoretical CS is said to run on a **Turing Machine**, which represents a model of **universal computation**; anything that can be solved by a computer program can also be solved by a Turing Machine.
  - Incidentally, when we talk about the time and space complexity of a Java program, the formal definition actually uses the equivalent Turing machine for precise definitions of "one unit of time" and "one unit of memory".
  - One major difference between a Java/Python program and a Turing machine is that the Turing machine has infinite memory.
  - A programming language is said to be **Turing-Complete** (å›¾çµå®Œå¤‡) if any Turing machine can be simulated with a program written in that language.

#### Deterministic Turing Machines

- A Turing machine with no randomness involved, or a **DTM**.
- Further, we will define the set **P** as the set of all decision problems that can be solved with a deterministic Turing Machine in **polynomial time**.
- Examples:
  - Is this array of length N sorted?
  - Does there exist a spanning tree of this graph (with N nodes) smaller than X weight?

#### Nondeterministic Turing Machines

- A **Nondeterministic Turing Machine** or **NTM** is a Turing Machine with one additional operation that can be performed: guessing.
  - Informally, we allow an operation int guess(int min, int max) that returns a number between min and max.
  - If ANY pattern of guesses ends up causing us to return True, then the nondeterministic Turing Machine returns True.
  - If ALL guess patterns return False, then the nondeterministic Turing Machine returns False.
- The set **NP** is the set of problems that can be solved in **polynomial time** with a NTM.
- å³çŒœä¸€ä¸ªç­”æ¡ˆ, è¯¥ç­”æ¡ˆå¯åœ¨å¤šé¡¹å¼æ—¶é—´å…§è¢«éªŒè¯æ­£ç¡®ä¸å¦. NTMå…è®¸**åŒæ—¶**éªŒè¯æ‰€æœ‰ç­”æ¡ˆ. (å¼€è¶³å¤Ÿå¤šä¸ªå¤šå…ƒå®‡å®™, éªŒè¯æ˜¯å¦æœ‰ä¸€ä¸ªå®‡å®™é‡Œçš„ç­”æ¡ˆæ˜¯æ­£ç¡®çš„)

#### P=NP?

- We will call a problem **NP-Hard** if every problem in NP reduces to that problem (or in other words, that problem is at least as hard as every problem in NP)
- We call a problem that's both in NP and NP-Hard an **NP-Complete problem**. Any NP-Complete problem is the hardest problem in NP.
- If even one of these problems has a reduction to a problem in P (or a polynomial time solution was discovered for it), then **every other NP problem will also be solved in polynomial time**. (æ³¨æ„solveå’Œverifyçš„åŒºåˆ«)
- This is the **P=NP problem**: Find a Turing reduction from an NP problem to P (P = NP), or prove that no reduction exists (P != NP).

## Summary

>  è¿™ä¸€éƒ¨åˆ†ç…§æ¬Lec40çš„slide

![](../0_Attachment/[61B%20SP24]%20Lecture%2040%20-%20Summary%20(0).jpg)

![](../0_Attachment/[61B%20SP24]%20Lecture%2040%20-%20Summary%20(1).jpg)

![](../0_Attachment/[61B%20SP24]%20Lecture%2040%20-%20Summary%20(2).jpg)

![](../0_Attachment/[61B%20SP24]%20Lecture%2040%20-%20Summary%20(3).jpg)

![](../0_Attachment/[61B%20SP24]%20Lecture%2040%20-%20Summary%20(4).jpg)

![](../0_Attachment/[61B%20SP24]%20Lecture%2040%20-%20Summary%20(5).jpg)

![](../0_Attachment/[61B%20SP24]%20Lecture%2040%20-%20Summary%20(6).jpg)